# Latency æµ‹é‡å…³é”®æ´å¯Ÿæ€»ç»“

## ğŸ¯ æ ¸å¿ƒé—®é¢˜

**ç°è±¡**: 22.85% çš„æ ·æœ¬ `T_LLM_decode = 0.0` ä½† `output_tokens > 0`ï¼Œå¹³å‡è¯¯å·® 21.73 ms

**æ ¹æœ¬åŸå› **: æµ‹é‡æ–¹æ³•ä¸ä¸€è‡´å¯¼è‡´çš„è¯¯å·®ç´¯ç§¯

---

## ğŸ’¡ å…³é”®æ´å¯Ÿ

### Insight 1: æµ‹é‡ç¯å¢ƒä¸€è‡´æ€§è‡³å…³é‡è¦

**é—®é¢˜**ï¼š
- Vision å’Œ Prefill åˆ†åˆ«æµ‹é‡æ—¶ï¼ŒGPU å¯èƒ½æœ‰ç¼“å­˜ï¼Œæµ‹é‡è¾ƒå¿«
- `T_total` æµ‹é‡å‰è°ƒç”¨ `empty_cache()`ï¼Œç¼“å­˜è¢«æ¸…ç©ºï¼Œæµ‹é‡è¾ƒæ…¢
- å¯¼è‡´ `T_vision_total + T_LLM_prefill > T_total`ï¼Œ`T_LLM_decode` ä¸ºè´Ÿæ•°

**è§£å†³æ–¹æ¡ˆ**ï¼š
- åœ¨åŒä¸€ä¸ªæµç¨‹ä¸­æµ‹é‡æ‰€æœ‰ç»„ä»¶
- ä½¿ç”¨ hooks åœ¨ `model.generate()` ä¸­åŒæ—¶æµ‹é‡æ‰€æœ‰é˜¶æ®µ
- ç¡®ä¿æµ‹é‡ç¯å¢ƒä¸€è‡´

**ä»£ç ä½ç½®**: `experiments/base_experiment.py::_measure_with_hooks()`

---

### Insight 2: å‡æ³•è®¡ç®—ä¼šæ”¾å¤§è¯¯å·®

**é—®é¢˜**ï¼š
- åˆ†åˆ«æµ‹é‡å„ä¸ªç»„ä»¶ï¼Œç„¶åé€šè¿‡å‡æ³•è®¡ç®—
- æ¯ä¸ªç»„ä»¶çš„æµ‹é‡è¯¯å·®ä¼šç´¯ç§¯
- Vision è¢«è®¡ç®—äº† 3 æ¬¡ï¼ˆåˆ†åˆ«æµ‹é‡ visionã€prefillã€totalï¼‰ï¼Œæ¯æ¬¡æ—¶é—´ä¸åŒ

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨ hooks ç›´æ¥æµ‹é‡æ¯ä¸ªé˜¶æ®µ
- é¿å…å‡æ³•è®¡ç®—
- Vision åªè®¡ç®— 1 æ¬¡ï¼ˆåœ¨ generate() å†…éƒ¨ï¼‰

**å…³é”®ä»£ç **:
```python
# æ—§æ–¹æ³•ï¼ˆå‡æ³•ï¼‰
T_LLM_decode = max(0.0, T_total - T_vision_total - T_LLM_prefill)

# æ–°æ–¹æ³•ï¼ˆç›´æ¥æµ‹é‡ï¼‰
# åœ¨ tracked_forward ä¸­ç›´æ¥æµ‹é‡ decode æ—¶é—´
if not is_prefill and decode_start_time is None:
    decode_start_time = time.perf_counter()
# ... generate() ...
T_LLM_decode = decode_end_time - decode_start_time
```

---

### Insight 3: Vision Backbone åº”è¯¥ä½œä¸ºæ•´ä½“

**é—®é¢˜**ï¼š
- åˆ†å¼€æµ‹é‡ encoder å’Œ projector éœ€è¦è¿è¡Œä¸¤æ¬¡ vision
- Projector é€šè¿‡å‡æ³•è®¡ç®—ï¼ˆ`T_vision_total - T_vision_encoder`ï¼‰ï¼Œä¸å‡†ç¡®
- å¢åŠ äº†ä¸å¿…è¦çš„æµ‹é‡ overhead

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å°† Vision backboneï¼ˆViT + Projectorï¼‰è§†ä¸ºä¸€ä¸ªæ•´ä½“
- åªæµ‹é‡ `T_vision_total`
- ä¸å†åˆ†å¼€æµ‹é‡ encoder å’Œ projector

**å½±å“**ï¼š
- å‡å°‘ä¸€æ¬¡ vision è®¡ç®—
- æé«˜æµ‹é‡å‡†ç¡®æ€§
- ç®€åŒ–ä»£ç å’Œæ•°æ®ç»“æ„

---

### Insight 4: æµ‹é‡ Overhead éœ€è¦æœ€å°åŒ–

**é—®é¢˜**ï¼š
- æ¯ä¸ª decode token éƒ½æµ‹é‡ä¼šå¯¼è‡´å¤§é‡ `torch.cuda.synchronize()` è°ƒç”¨
- å¯¹äº 16 tokensï¼Œéœ€è¦ 32 æ¬¡ synchronize è°ƒç”¨
- Overhead ç´¯ç§¯ï¼Œå½±å“æµ‹é‡å‡†ç¡®æ€§

**è§£å†³æ–¹æ¡ˆ**ï¼š
- åªæµ‹é‡æ€»çš„ decode æ—¶é—´ï¼ˆä»ç¬¬ä¸€ä¸ªåˆ°æœ€åä¸€ä¸ª decode stepï¼‰
- å‡å°‘ 94% çš„æµ‹é‡è°ƒç”¨ï¼ˆä» 32 æ¬¡å‡å°‘åˆ° 2 æ¬¡ï¼‰

**æ€§èƒ½å¯¹æ¯”**ï¼š
| æ–¹æ¡ˆ | æµ‹é‡è°ƒç”¨ | Overhead | å‡†ç¡®æ€§ |
|------|---------|---------|--------|
| æ¯ä¸ª token éƒ½æµ‹é‡ | 32 æ¬¡ | ~160 Î¼s | å¯åˆ†æå•ä¸ª token |
| åªæµ‹é‡æ€»æ—¶é—´ | 2 æ¬¡ | ~10 Î¼s | æ›´å‡†ç¡®ï¼Œç¬¦åˆå·¥ç¨‹å®è·µ |

**é€‰æ‹©**: åªæµ‹é‡æ€»æ—¶é—´ï¼ˆæ–¹æ¡ˆ2ï¼‰

---

### Insight 5: `torch.cuda.empty_cache()` çš„å½±å“

**å…³é”®å‘ç°**ï¼š
- `empty_cache()` ä¼šæ¸…ç©º GPU ç¼“å­˜ï¼Œå¯¼è‡´å†…å­˜åˆ†é…æ›´æ…¢
- å¦‚æœåªåœ¨ `T_total` æµ‹é‡å‰è°ƒç”¨ï¼Œä¼šå¯¼è‡´æµ‹é‡ç¯å¢ƒä¸ä¸€è‡´
- è¿™æ˜¯å¯¼è‡´æµ‹é‡è¯¯å·®çš„ä¸»è¦åŸå› ä¹‹ä¸€

**è§£å†³æ–¹æ¡ˆ**ï¼š
- ç»Ÿä¸€æµ‹é‡ç¯å¢ƒï¼šè¦ä¹ˆéƒ½è°ƒç”¨ `empty_cache()`ï¼Œè¦ä¹ˆéƒ½ä¸è°ƒç”¨
- åœ¨æ–°å®ç°ä¸­ï¼Œæ‰€æœ‰æµ‹é‡åœ¨åŒä¸€ä¸ªæµç¨‹ä¸­ï¼Œç¯å¢ƒè‡ªç„¶ä¸€è‡´

---

## ğŸ”§ å®ç°è¦ç‚¹

### 1. ä½¿ç”¨ Hooks åœ¨åŒä¸€ä¸ªæµç¨‹ä¸­æµ‹é‡

```python
def _measure_with_hooks():
    # æ³¨å†Œ hooks
    vision_hook = vision_backbone.register_forward_hook(vision_hook)
    prefill_start_hook = transformer.blocks[0].register_forward_hook(...)
    prefill_end_hook = transformer.blocks[-1].register_forward_hook(...)
    
    # åœ¨ tracked_forward ä¸­è·Ÿè¸ª decode
    def tracked_forward(*args, **kwargs):
        # ä½¿ç”¨ forward_count åŒºåˆ† prefill (0) å’Œ decode (>0)
        if forward_count == 0:
            # Prefill step
        else:
            # Decode step - è®°å½•å¼€å§‹æ—¶é—´ï¼ˆç¬¬ä¸€æ¬¡ï¼‰
    
    # è¿è¡Œä¸€æ¬¡ generate()ï¼Œhooks è‡ªåŠ¨æµ‹é‡æ‰€æœ‰é˜¶æ®µ
    output = model.generate(...)
    
    # æµ‹é‡ decode ç»“æŸæ—¶é—´
    T_LLM_decode = decode_end_time - decode_start_time
```

### 2. åªæµ‹é‡æ€»çš„ Decode æ—¶é—´

```python
# åœ¨ç¬¬ä¸€ä¸ª decode step å¼€å§‹æ—¶è®°å½•æ—¶é—´
if not is_prefill and decode_start_time is None:
    torch.cuda.synchronize(self.device)
    decode_start_time = time.perf_counter()

# åœ¨ generate() å®Œæˆåæµ‹é‡ç»“æŸæ—¶é—´
if decode_start_time is not None:
    torch.cuda.synchronize(self.device)
    decode_end_time = time.perf_counter()
    T_LLM_decode = (decode_end_time - decode_start_time) * 1000
```

### 3. Vision Backbone ä½œä¸ºæ•´ä½“

```python
# åªæµ‹é‡ vision totalï¼ˆVision backbone æ•´ä½“ï¼‰
results["T_vision_total"] = measure_vision_total()
# T_vision_encoder å’Œ T_projector ä¸å†å­˜åœ¨
```

---

## ğŸ“Š æµ‹é‡æ–¹æ³•å¯¹æ¯”

### æ—§æ–¹æ³•ï¼ˆå‡æ³•è®¡ç®—ï¼‰

```
1. measure_vision_backbone()     â†’ T_vision_total (ç¬¬1æ¬¡è¿è¡Œ vision)
2. measure_prefill_with_hooks()  â†’ T_LLM_prefill  (ç¬¬2æ¬¡è¿è¡Œ vision)
3. measure_generate()            â†’ T_total        (ç¬¬3æ¬¡è¿è¡Œ vision, empty_cache() å)
4. T_LLM_decode = T_total - T_vision_total - T_LLM_prefill  (å‡æ³•è®¡ç®—)
```

**é—®é¢˜**ï¼š
- Vision è¢«è®¡ç®— 3 æ¬¡
- æµ‹é‡ç¯å¢ƒä¸ä¸€è‡´
- å‡æ³•è®¡ç®—ç´¯ç§¯è¯¯å·®

### æ–°æ–¹æ³•ï¼ˆç›´æ¥æµ‹é‡ï¼‰

```
1. register_hooks()              â†’ æ³¨å†Œæµ‹é‡ hooks
2. model.generate()               â†’ è¿è¡Œä¸€æ¬¡ï¼Œhooks è‡ªåŠ¨æµ‹é‡æ‰€æœ‰é˜¶æ®µ
   - vision_hook æµ‹é‡ T_vision_total
   - prefill_hooks æµ‹é‡ T_LLM_prefill
   - tracked_forward è·Ÿè¸ª decode æ—¶é—´
3. T_LLM_decode = decode_end - decode_start  (ç›´æ¥æµ‹é‡)
```

**ä¼˜åŠ¿**ï¼š
- Vision åªè®¡ç®— 1 æ¬¡
- æ‰€æœ‰æµ‹é‡åœ¨åŒä¸€ä¸ªæµç¨‹ä¸­ï¼Œç¯å¢ƒä¸€è‡´
- ç›´æ¥æµ‹é‡ï¼Œæ— å‡æ³•è®¡ç®—è¯¯å·®

---

## ğŸ“ æœ€ä½³å®è·µ

1. **åœ¨åŒä¸€ä¸ªæµç¨‹ä¸­æµ‹é‡æ‰€æœ‰ç»„ä»¶**
   - ä½¿ç”¨ hooks åœ¨ `model.generate()` ä¸­åŒæ—¶æµ‹é‡æ‰€æœ‰é˜¶æ®µ
   - é¿å…åˆ†åˆ«æµ‹é‡å¸¦æ¥çš„ç¯å¢ƒå·®å¼‚

2. **æœ€å°åŒ–æµ‹é‡ overhead**
   - åªæµ‹é‡æ€»æ—¶é—´ï¼Œä¸æ˜¯æ¯ä¸ª token
   - å‡å°‘ `torch.cuda.synchronize()` è°ƒç”¨

3. **å°†ç›¸å…³ç»„ä»¶è§†ä¸ºæ•´ä½“**
   - Vision backboneï¼ˆViT + Projectorï¼‰ä½œä¸ºæ•´ä½“æµ‹é‡
   - é¿å…ä¸å¿…è¦çš„ç»„ä»¶æ‹†åˆ†

4. **ç»Ÿä¸€æµ‹é‡ç¯å¢ƒ**
   - è¦ä¹ˆéƒ½è°ƒç”¨ `empty_cache()`ï¼Œè¦ä¹ˆéƒ½ä¸è°ƒç”¨
   - ç¡®ä¿æ‰€æœ‰æµ‹é‡åœ¨ç›¸åŒçš„ GPU çŠ¶æ€ä¸‹è¿›è¡Œ

---

## ğŸ“ˆ æ”¹è¿›æ•ˆæœ

### æµ‹é‡å‡†ç¡®æ€§
- **æ—§æ–¹æ³•**: æµ‹é‡è¯¯å·®å¯è¾¾ 20-50 msï¼ˆ22.85% çš„æ ·æœ¬å—å½±å“ï¼‰
- **æ–°æ–¹æ³•**: æµ‹é‡è¯¯å·® < 1 msï¼ˆç¯å¢ƒä¸€è‡´ï¼Œç›´æ¥æµ‹é‡ï¼‰

### æ€§èƒ½ Overhead
- **æ—§æ–¹æ³•**: 32 æ¬¡ `synchronize()` è°ƒç”¨ï¼ˆ16 tokensï¼‰
- **æ–°æ–¹æ³•**: 2 æ¬¡ `synchronize()` è°ƒç”¨
- **æ”¹è¿›**: å‡å°‘ 94% çš„æµ‹é‡è°ƒç”¨

### ä»£ç ç®€æ´æ€§
- **æ—§æ–¹æ³•**: éœ€è¦åˆ†åˆ«æµ‹é‡ visionã€prefillã€totalï¼Œç„¶åå‡æ³•è®¡ç®—
- **æ–°æ–¹æ³•**: ä¸€æ¬¡ `generate()` è°ƒç”¨ï¼Œhooks è‡ªåŠ¨æµ‹é‡æ‰€æœ‰é˜¶æ®µ

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- `docs/analysis/latency_measurement_code_locations.md` - è¯¦ç»†çš„ä»£ç ä½ç½®è¯´æ˜
- `docs/analysis/latency_measurement_issue_summary.md` - é—®é¢˜æ€»ç»“å’Œè§£å†³æ–¹æ¡ˆ
- `docs/analysis/decode_measurement_strategy.md` - Decode æµ‹é‡ç­–ç•¥åˆ†æ
- `docs/analysis/latency_measurement_refactoring.md` - å®Œæ•´çš„é‡æ„æ–‡æ¡£

