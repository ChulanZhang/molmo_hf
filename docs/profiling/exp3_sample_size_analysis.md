# EXP3 样本数配置分析

## 当前配置

- **每个数据集**: 1,000 样本
- **数据来源**: train+validation 组合（从组合后的数据集中均匀采样）
- **数据集数量**: 8 个
- **总样本数**: 8,000 样本（8 数据集 × 1,000）

## 样本数合理性分析

### 1. 统计显著性要求

**重要性分析的需求**：
- **最小样本数**: 500-1,000 样本（用于重要性排序）
- **推荐样本数**: 1,000-2,000 样本（用于更稳定的估计）
- **理想样本数**: 2,000-5,000 样本（用于高精度估计）

**当前配置 (1,000 样本)**：
- ✅ 满足最小要求
- ✅ 达到推荐范围的下限
- ⚠️ 略低于理想范围，但对于重要性排序应该足够

### 2. Spearman 相关性的样本需求

**Spearman 相关性**主要依赖于**排序**，而不是绝对数值：
- 对于 16 个 block 的排序，1,000 样本应该足够
- 之前实验显示，即使样本数较少，相关性仍然稳定
- 例如：`st_qa` (1,024 validation samples) 达到 0.9882 的相关性

### 3. 跨数据集验证的优势

**8 个数据集提供**：
- **跨任务验证**：不同任务类型（VQA、Caption、Document QA等）
- **跨数据分布验证**：不同数据来源和复杂度
- **统计鲁棒性**：即使单个数据集样本数略少，多个数据集的结果可以相互验证

### 4. 实验时间考虑

**之前配置 (5,000 样本/数据集)**：
- 单个数据集运行时间：~3-4 小时
- 8 个数据集：~24-32 小时

**当前配置 (1,000 样本/数据集)**：
- 单个数据集运行时间：~1 小时（估计）
- 8 个数据集：~8 小时（估计）
- **时间节省**: ~70%

### 5. 样本分布策略

**推荐方式**：从组合后的数据集中均匀采样
- ✅ 自动平衡 train 和 validation 的样本
- ✅ 如果某个 split 样本不足，自动使用全部可用样本
- ✅ 保持数据多样性

**不推荐**：分别从 train 和 validation 各采样 500
- ❌ 可能无法充分利用数据（如果某个 split 样本很多）
- ❌ 需要手动平衡

## 数据集特定考虑

### 大型数据集 (>= 20K 样本)

| 数据集 | Validation 样本数 | 1,000 样本覆盖率 |
|--------|-------------------|------------------|
| coco_2014_vqa | 214,354 | 0.47% |
| coco_caption | 40,504 | 2.47% |
| tally_qa | 26,451 | 3.78% |

**结论**：覆盖率很低，但统计显著性应该足够（大样本量提供稳定的分布）

### 中型数据集 (5K-20K 样本)

| 数据集 | Validation 样本数 | 1,000 样本覆盖率 |
|--------|-------------------|------------------|
| doc_qa | 5,349 | 18.7% |
| okvqa | 5,046 | 19.8% |
| text_vqa | 5,000 | 20.0% |

**结论**：覆盖率适中，应该足够进行重要性分析

### 小型数据集 (< 5K 样本)

| 数据集 | Validation 样本数 | 1,000 样本覆盖率 |
|--------|-------------------|------------------|
| science_qa_img | 2,097 | 47.7% |
| st_qa | 1,024 | 97.7% |

**结论**：
- `science_qa_img`: 会使用大部分样本，应该足够
- `st_qa`: 会使用几乎所有样本（如果 train+validation 组合后仍接近 1,024）

## 建议

### ✅ 推荐配置（当前）

```python
num_samples = 1000  # Per dataset, from combined train+validation
```

**理由**：
1. 满足统计显著性要求（达到推荐范围下限）
2. 大幅减少实验时间（~70% 时间节省）
3. 8 个数据集提供跨任务验证
4. Spearman 相关性主要依赖排序，1,000 样本应该足够

### ⚠️ 如果时间允许，可以考虑

```python
num_samples = 2000  # Per dataset, from combined train+validation
```

**优势**：
- 更高的统计显著性
- 更稳定的重要性分数估计
- 但实验时间会增加 ~100%

### ❌ 不推荐低于 1,000

**原因**：
- 低于统计显著性推荐范围
- 可能导致重要性分数估计不稳定
- 特别是对于小型数据集

## 实施细节

### 采样方式

代码会自动：
1. 加载 train 和 validation split
2. 使用 `ConcatDataset` 组合
3. 从组合后的数据集中均匀采样 1,000 样本
4. 如果总样本数 < 1,000，使用全部样本

### 示例

对于 `coco_2014_vqa`：
- Train: ~443,757 样本
- Validation: ~214,354 样本
- 组合后: ~658,111 样本
- 采样: 1,000 样本（均匀分布）

对于 `st_qa`：
- Train: ~1,024 样本（估计）
- Validation: ~1,024 样本
- 组合后: ~2,048 样本
- 采样: 1,000 样本（如果总样本数 > 1,000）

## 结论

**1,000 样本/数据集是合理的配置**，因为：

1. ✅ **满足统计要求**：达到推荐范围下限
2. ✅ **时间效率**：大幅减少实验时间
3. ✅ **跨数据集验证**：8 个数据集提供鲁棒性
4. ✅ **排序稳定性**：Spearman 相关性主要依赖排序，1,000 样本足够

**建议**：先使用 1,000 样本运行实验，如果结果不稳定或需要更高精度，再考虑增加到 2,000。


