# 数据集样本数量汇总

本文档记录了实验中使用的所有数据集的样本数量，用于指导实验配置和样本采样策略。

## 数据集样本数

| 数据集 | Split | 样本数 | 备注 |
|--------|-------|--------|------|
| **coco_2014_vqa** | validation | **214,354** | 最大数据集 |
| **coco_caption** | validation | **40,504** | 第二大 |
| **tally_qa** | test | **26,451** | |
| **doc_qa** | validation | **5,349** | |
| **okvqa** | validation | **5,046** | |
| **text_vqa** | validation | **5,000** | |
| **science_qa_img** | validation | **2,097** | |
| **st_qa** | validation | **1,024** | |
| **mmmu** | validation | **900** | 最小数据集 |

**总计**: 304,625 个样本  
**平均样本数**: 33,847

## 数据集分类

### 大型数据集 (>= 20K 样本)
- **coco_2014_vqa**: 214,354 样本
- **coco_caption**: 40,504 样本
- **tally_qa**: 26,451 样本

### 中型数据集 (5K-20K 样本)
- **doc_qa**: 5,349 样本
- **okvqa**: 5,046 样本
- **text_vqa**: 5,000 样本

### 小型数据集 (< 5K 样本)
- **science_qa_img**: 2,097 样本
- **st_qa**: 1,024 样本
- **mmmu**: 900 样本

## 实验配置建议

### 当前默认配置
- `num_samples = 1000`
- `num_runs_per_sample = 3`

### 对于 scale 实验的推荐配置

#### 方案 1: 统一扩展到 2000（推荐）
```python
num_samples = 2000  # 对所有数据集统一使用
```

**覆盖率分析**:
- **大型数据集** (>= 20K):
  - coco_2014_vqa: 2000/214,354 = **0.9%**
  - coco_caption: 2000/40,504 = **4.9%**
  - tally_qa: 2000/26,451 = **7.6%**

- **中型数据集** (5K-20K):
  - doc_qa: 2000/5,349 = **37.4%**
  - okvqa: 2000/5,046 = **39.6%**
  - text_vqa: 2000/5,000 = **40.0%**

- **小型数据集** (< 5K):
  - science_qa_img: 2000/2,097 = **95.4%** (实际会使用全部 2,097)
  - st_qa: 2000/1,024 = **195.5%** (实际会使用全部 1,024)
  - mmmu: 2000/900 = **222.2%** (实际会使用全部 900)

**优点**:
- 统一配置，简单易用
- 大型数据集有足够的统计显著性
- 中型数据集覆盖率高
- 小型数据集自动使用全部样本

#### 方案 2: 按数据集大小调整
```python
# 大型数据集 (>= 20K)
large_datasets = ["coco_2014_vqa", "coco_caption", "tally_qa"]
num_samples_large = 5000

# 中型数据集 (5K-20K)
medium_datasets = ["doc_qa", "okvqa", "text_vqa"]
num_samples_medium = 3000

# 小型数据集 (< 5K)
small_datasets = ["science_qa_img", "st_qa", "mmmu"]
num_samples_small = None  # 使用全部样本
```

**覆盖率分析**:
- **大型数据集**:
  - coco_2014_vqa: 5000/214,354 = **2.3%**
  - coco_caption: 5000/40,504 = **12.3%**
  - tally_qa: 5000/26,451 = **18.9%**

- **中型数据集**:
  - doc_qa: 3000/5,349 = **56.1%**
  - okvqa: 3000/5,046 = **59.5%**
  - text_vqa: 3000/5,000 = **60.0%**

- **小型数据集**: 使用全部样本

**优点**:
- 针对不同数据集大小优化
- 大型数据集有更好的统计显著性
- 中型数据集有更高的覆盖率
- 小型数据集使用全部样本

#### 方案 3: 高精度配置（如果时间允许）
```python
# 大型数据集
num_samples_large = 10000

# 中型数据集
num_samples_medium = 5000  # 接近全部样本

# 小型数据集
num_samples_small = None  # 使用全部样本
```

## 实验时间估算

假设单个样本运行时间 = T，`num_runs_per_sample = 3`:

### 方案 1 (num_samples = 2000)
- 每个数据集: 2000 × 3 × T = 6000T
- 9 个数据集总计: 54,000T

### 方案 2 (按大小调整)
- 大型数据集 (3个): 3 × 5000 × 3 × T = 45,000T
- 中型数据集 (3个): 3 × 3000 × 3 × T = 27,000T
- 小型数据集 (3个): (2,097 + 1,024 + 900) × 3 × T ≈ 12,063T
- 总计: 84,063T

### 方案 3 (高精度)
- 大型数据集 (3个): 3 × 10000 × 3 × T = 90,000T
- 中型数据集 (3个): 3 × 5000 × 3 × T = 45,000T
- 小型数据集 (3个): (2,097 + 1,024 + 900) × 3 × T ≈ 12,063T
- 总计: 147,063T

## 注意事项

1. **小型数据集限制**:
   - `st_qa` (1,024) 和 `mmmu` (900) 样本数较少
   - 如果 `num_samples` 超过实际样本数，会自动使用全部样本
   - 建议对小型数据集使用 `num_samples = None` 或设置较小的值

2. **统计显著性**:
   - 对于准确度估计，建议至少 1000-2000 样本
   - 对于延迟分布估计（P95, P99），建议至少 2000-5000 样本

3. **实验时间**:
   - 增加 `num_samples` 会线性增加实验时间
   - 建议根据可用计算资源选择合适的配置

4. **采样策略**:
   - 当前使用 `balanced` 采样策略，确保样本多样性
   - 使用固定随机种子 (seed=66) 确保可重复性

## 相关文档

- [实验配置指南](../core_exp/README.md)
- [num_samples vs num_runs_per_sample 分析](../core_exp/num_samples_vs_runs_analysis.md) (如果存在)

## 更新历史

- 2025-01-XX: 初始版本，记录所有 9 个数据集的样本数量

