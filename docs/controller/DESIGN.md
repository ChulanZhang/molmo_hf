# Controllerè®¾è®¡æ–‡æ¡£ï¼ˆç»Ÿä¸€ç‰ˆï¼‰

> **æ–‡æ¡£çŠ¶æ€**: æœ¬æ–‡æ¡£æ•´åˆäº†æ‰€æœ‰controllerè®¾è®¡æ–‡æ¡£ï¼ŒåŸºäºç°æœ‰ä»£ç å®ç°å’ŒSIGMETRICSæ ‡å‡†ã€‚
> **æœ€åæ›´æ–°**: 2026-01-10
> **ç‰ˆæœ¬**: 3.0 (Joint Training Only)

## ç›®å½•

1. [è®¾è®¡æ¦‚è¿°](#1-è®¾è®¡æ¦‚è¿°)
2. [ç³»ç»Ÿçº¦æŸä¸æ‰§è¡Œæµç¨‹](#2-ç³»ç»Ÿçº¦æŸä¸æ‰§è¡Œæµç¨‹)
3. [æ¶æ„è®¾è®¡](#3-æ¶æ„è®¾è®¡)
4. [Knobè®¾è®¡ç»†èŠ‚](#4-knobè®¾è®¡ç»†èŠ‚)
5. [è¾“å…¥ç‰¹å¾è®¾è®¡](#5-è¾“å…¥ç‰¹å¾è®¾è®¡)
6. [è®­ç»ƒæ–¹æ³•](#6-è®­ç»ƒæ–¹æ³•)
7. [Overheadåˆ†æ](#7-overheadåˆ†æ)
8. [å®ç°ç»†èŠ‚](#8-å®ç°ç»†èŠ‚)
9. [æ€§èƒ½æŒ‡æ ‡](#9-æ€§èƒ½æŒ‡æ ‡)
10. [å…³é”®è®¾è®¡å†³ç­–](#10-å…³é”®è®¾è®¡å†³ç­–)

---

## 1. è®¾è®¡æ¦‚è¿°

### 1.1 è®¾è®¡ç›®æ ‡

**SIGMETRICSæ ‡å‡†**ï¼š
1. **ä½Overhead**: Controllerå¼€é”€ <0.1% of total inference
2. **é«˜æ•ˆæ€§**: å†³ç­–æ—¶é—´ <0.2ms
3. **æœ‰æ•ˆæ€§**: æ˜¾è‘—æå‡accuracy-latency trade-off
4. **ç®€æ´æ€§**: è®¾è®¡ç®€å•ï¼Œæ˜“äºéƒ¨ç½²
5. **å¯æ‰©å±•æ€§**: é€‚ç”¨äºä¸åŒç¡¬ä»¶å’Œæ¨¡å‹è§„æ¨¡

### 1.2 æ ¸å¿ƒè®¾è®¡ç†å¿µ

**ä¸¤é˜¶æ®µé¢„æµ‹æ¶æ„**ï¼š
- **Stage 1**: åœ¨vision encoderä¹‹å‰é¢„æµ‹Knob1ï¼ˆvision tokens tierï¼‰
- **Stage 2**: åœ¨vision encoderä¹‹åé¢„æµ‹Knob2 & Knob3ï¼ˆMoE top-Kå’Œtransformer blocksï¼‰

**å…³é”®åŸåˆ™**ï¼š
- æœ€å°åŒ–controllerå¼€é”€
- ç¬¦åˆç³»ç»Ÿæ‰§è¡Œæµç¨‹çº¦æŸ
- ä½¿ç”¨importance-based pruningç®€åŒ–Knob3

### 1.3 ä¸‰ä¸ªKnobçš„æœ€ç»ˆè®¾è®¡

| Knob | æ§åˆ¶å†…å®¹ | å†³ç­–æ—¶æœº | å®ç°æ–¹å¼ | è¾“å‡ºç©ºé—´ |
|------|---------|---------|---------|---------|
| **Knob1** | Vision tokens tier (low/medium/high) + Insertion Position (1-5) | Before vision encoder | Stage 1 predictor | 3 tiers Ã— 5 positions |
| **Knob2** | MoE top-K (4/5/6/7/8) | After insertion position | Stage 2 predictor | 5 choices |
| **Knob3** | Transformer blocks count (12/13/14/15/16 total blocks) | After insertion position | **Importance-based pruning** | 5 choices |

**å…³é”®æ”¹è¿›**ï¼š
- Knob3ä»maské¢„æµ‹ï¼ˆ2^16ï¼‰ç®€åŒ–ä¸ºnum_blocksé¢„æµ‹ï¼ˆ5ï¼‰ï¼ŒåŸºäºé¢„è®¡ç®—çš„importance score
- Block selectionæ˜¯ç¡®å®šæ€§çš„ï¼Œä¸ä¾èµ–è¾“å…¥

---

## 2. ç³»ç»Ÿçº¦æŸä¸æ‰§è¡Œæµç¨‹

### 2.1 ç³»ç»Ÿçº¦æŸ

**VLMæ¶æ„**: `Vision Encoder â†’ Projector â†’ LLM`

**å…³é”®çº¦æŸ**ï¼š
1. **Knob1**: å¿…é¡»åœ¨vision encoderä¹‹å‰å†³å®š
   - Cropæ•°é‡å†³å®šå›¾åƒå¤„ç†æ–¹å¼ï¼ˆtiling, resizeï¼‰
   - ä¸€æ—¦è¿›å…¥vision encoderï¼Œcropæ•°é‡å°±å›ºå®šäº†
2. **Knob2 & Knob3**: å¿…é¡»åœ¨LLMå‰å‡ å±‚æˆ–ä¹‹å‰å†³å®š
   - Top-Kå’Œblockså½±å“åç»­è®¡ç®—
   - é¿å…é‡å¤è®¡ç®—

### 2.2 æ‰§è¡Œæµç¨‹

```
1. Input: Image + Prompt + Latency Budget
    â†“
2. Stage 1: Predict Knob1
   - Extract: Language Feature (from prompt)
   - Extract: Budget Token (encoded as d_model-dim token, concatenated to input)
   - Predict: Vision Tokens Tier (low/medium/high) + Insertion Position (1-5)
   - Overhead: ~0.01-0.1ms
    â†“
3. Image Preprocessing (based on Knob1 tier)
   - Determine crop count from tier
   - Apply tiling and resize
    â†“
4. Vision Encoding
   - Vision Encoder: Process crops
   - Projector: Map to LLM space
    â†“
5. LLM Forward to Insertion Position
   - Run LLM blocks up to insertion position
   - Extract: Latency Token (last token after insertion position)
    â†“
6. Stage 2: Predict Knob2 & Knob3
   - Input: Latency Token (contains budget + vision + language interaction)
   - Predict: MoE Top-K (4/5/6/7/8) + Total Blocks (12/13/14/15/16)
   - Overhead: ~0.1ms
    â†“
7. Apply Knobs to Remaining LLM Blocks
   - Set top_k for blocks after insertion position (zero overhead, attribute modification)
   - Select blocks by importance (deterministic, O(n log n))
   - First block fixed: top_k=8, always included
    â†“
8. LLM Forward (with adaptive knobs)
   - Prefill: Generate with all knobs applied
   - Decode: Use prefill configuration (no controller re-run)
   - Generate output
```

### 2.3 è®­ç»ƒæ—¶æµç¨‹ï¼ˆJoint GRPO Trainingï¼‰

```
1. Controller predicts knob configuration
   - Stage 1: Predict Knob1 (tier + insertion position)
   - Process images with Knob1 tier
   - Vision encoding
   - Run LLM to insertion position, extract latency token
   - Stage 2: Predict Knob2 & Knob3 (based on latency token)
    â†“
2. Execute model (real execution, batch_size=1 per sample)
   - Use predicted knobs
   - Measure actual latency using hooks (prefill + decode)
   - Get accuracy from model output
    â†“
3. Compute reward
   - accuracy + latency constraints + budget violation penalty
    â†“
4. Update controller (Joint GRPO)
   - Both Stage1 and Stage2 contribute to same reward
   - End-to-end optimization
```

**å…³é”®è®¾è®¡**:
- **Direct Latency Measurement**: ä½¿ç”¨PyTorch hooksç›´æ¥æµ‹é‡latencyï¼ˆä¸ä½¿ç”¨estimatorï¼‰
- **Batch Size**: æ¯ä¸ªæ ·æœ¬å•ç‹¬å¤„ç†ï¼ˆbatch_size=1 per sampleï¼‰ä»¥ç¡®ä¿å‡†ç¡®æµ‹é‡
- **Budget Token**: åœ¨prefillé˜¶æ®µç¼–ç ä¸ºtokenå¹¶æ‹¼æ¥åˆ°è¾“å…¥åºåˆ—
- **Decode Phase**: ä½¿ç”¨prefillé˜¶æ®µå†³å®šçš„é…ç½®ï¼Œä¸é‡æ–°è¿è¡Œcontroller

---

## 3. æ¶æ„è®¾è®¡

### 3.1 ä¸¤é˜¶æ®µæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Two-Stage Controller Architecture              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Stage 1: Knob1 Prediction (BEFORE Vision Encoder)        â”‚
â”‚  â”œâ”€ Input: Language Feature + Budget Token (encoded)      â”‚
â”‚  â”œâ”€ Network: Lightweight MLP                               â”‚
â”‚  â””â”€ Output: Tier (low/medium/high) + Insertion Position (1-5)â”‚
â”‚                                                              â”‚
â”‚  â†“ Image Preprocessing (based on Knob1 tier)              â”‚
â”‚  â†“ Vision Encoder + Projector                              â”‚
â”‚  â†“ LLM Forward to Insertion Position                       â”‚
â”‚  â†“ Extract Latency Token                                   â”‚
â”‚                                                              â”‚
â”‚  Stage 2: Knob2 & Knob3 Prediction (AFTER Insertion)       â”‚
â”‚  â”œâ”€ Input: Latency Token (from LLM)                        â”‚
â”‚  â”œâ”€ Network: Lightweight MLP                               â”‚
â”‚  â””â”€ Output: Top-K (4/5/6/7/8) + Total Blocks (12-16)      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Stage 1: Knob1 Predictor

**è®¾è®¡é€‰é¡¹ï¼ˆä¸‰ä¸ªé€‰æ‹©ï¼Œå¤æ‚åº¦é€’å¢ï¼‰**ï¼š

#### é€‰é¡¹A: Budget-Onlyï¼ˆæœ€å°Overheadï¼Œæ¨èç”¨äºSIGMETRICSï¼‰
- **Input**: Latency Budget only
- **Network**: Tiny MLP (~10K params)
- **Overhead**: ~0.01ms
- **ä¼˜ç‚¹**: æœ€å°overheadï¼Œç®€å•ç›´æ¥
- **ç¼ºç‚¹**: æ— æ³•åˆ©ç”¨promptä¿¡æ¯
- **çŠ¶æ€**: âœ… ä¼˜å…ˆå®ç°

#### é€‰é¡¹B: Budget + Languageï¼ˆä¸­ç­‰å¤æ‚åº¦ï¼‰
- **Input**: Language Feature + Budget Feature
- **Network**: Lightweight MLP (~50K params) æˆ– Semantic Router
- **Overhead**: ~0.1ms
- **ä¼˜ç‚¹**: å¯ä»¥åˆ©ç”¨promptä¿¡æ¯ï¼Œæ›´æ™ºèƒ½çš„å†³ç­–
- **ç¼ºç‚¹**: ç¨é«˜çš„overhead
- **çŠ¶æ€**: ğŸ”„ è°ƒç ”Semantic Routeré›†æˆ
- **è°ƒç ”æ–¹å‘**: å‚è€ƒ [Semantic Router](https://github.com/aurelio-labs/semantic-router) è¿›è¡Œå¿«é€Ÿè¯­ä¹‰è·¯ç”±å†³ç­–

#### é€‰é¡¹C: Budget + Language + Visionï¼ˆæœ€é«˜å¤æ‚åº¦ï¼‰
- **Input**: Vision Feature (global crop) + Language Feature + Budget Feature
- **Network**: MLPæˆ–Transformer
- **Overhead**: ~30-50msï¼ˆéœ€è¦é¢å¤–è¿è¡Œvision encoderï¼‰
- **ä¼˜ç‚¹**: æœ€å‡†ç¡®ï¼Œå¯ä»¥åˆ©ç”¨å›¾åƒå¤æ‚åº¦ä¿¡æ¯
- **ç¼ºç‚¹**: éœ€è¦å¤šè¿‡ä¸€évision encoderï¼Œoverheadå¤§
- **çŠ¶æ€**: âš ï¸ éœ€è¦ä¼˜åŒ–å»ºè®®
- **ä¼˜åŒ–å»ºè®®**: 
  - è€ƒè™‘ä½¿ç”¨è½»é‡çº§vision encoderï¼ˆå¦‚MobileViTï¼‰
  - ç¼“å­˜global cropçš„vision feature
  - ä½¿ç”¨çŸ¥è¯†è’¸é¦è®­ç»ƒå°æ¨¡å‹

**å½“å‰ä»£ç å®ç°**: é€‰é¡¹Bï¼ˆ`controller.py`ä¸­çš„`Knob1PredictorBudgetLanguage`ï¼‰

**å…³é”®æ”¹è¿›**:
- åŒæ—¶é¢„æµ‹tierå’Œinsertion positionï¼ˆStage2æ’å…¥ä½ç½®ï¼‰
- Budget tokenç¼–ç ä¸ºd_modelç»´tokenï¼Œæ‹¼æ¥åˆ°è¾“å…¥åºåˆ—

### 3.3 Stage 2: Knob2 & Knob3 Predictor

**æ¶æ„**: ç‹¬ç«‹è½»é‡çº§MLP

```python
Latency Token (B, d_model)  # From LLM after insertion position
    â†“
Projection â†’ (B, hidden_dim)
    â†“
Fusion MLP â†’ (B, hidden_dim)
    â†“
Two Heads â†’ (B, 5) each [top_k: 4,5,6,7,8] [blocks: 12,13,14,15,16]
```

**å‚æ•°é‡**: ~10K-30K parametersï¼ˆè½»é‡çº§è®¾è®¡ï¼‰

**å…³é”®è®¾è®¡**:
- **åªä½¿ç”¨Latency Token**: å·²ç»åŒ…å«budgetã€visionå’Œlanguageçš„äº¤äº’ä¿¡æ¯
- **åŠ¨æ€æ’å…¥ä½ç½®**: Stage1é¢„æµ‹æ’å…¥ä½ç½®ï¼ˆ1-5ï¼‰ï¼ŒStage2åœ¨æ’å…¥ä½ç½®ä¹‹åè¿è¡Œ
- **åŠ¨æ€Knob3é€‰é¡¹**: æ ¹æ®æ’å…¥ä½ç½®åŠ¨æ€è°ƒæ•´å¯é€‰çš„blockæ•°é‡

---

## 4. Knobè®¾è®¡ç»†èŠ‚

### 4.1 Knob1: Vision Tokens Tier

**æ§åˆ¶å†…å®¹**: Vision tokensçš„æ•°é‡ï¼ˆé€šè¿‡tieræ§åˆ¶cropæ•°é‡ï¼‰

**å†³ç­–æ—¶æœº**: å¿…é¡»åœ¨vision encoderä¹‹å‰

**å®ç°æ–¹å¼**: Stage 1 predictor

**è¾“å‡º**: 3ä¸ªé€‰æ‹©ï¼ˆlow, medium, highï¼‰

**è¯¦ç»†è®¾è®¡**: å‚è§`knob1_predictor_variants.md`

### 4.2 Knob2: MoE Top-K

**æ§åˆ¶å†…å®¹**: MoEå±‚çš„expertæ•°é‡

**å†³ç­–æ—¶æœº**: åœ¨vision encoderä¹‹åï¼ŒLLMä¹‹å‰

**å®ç°æ–¹å¼**: Stage 2 predictor

**è¾“å‡º**: 5ä¸ªé€‰æ‹©ï¼ˆ4, 5, 6, 7, 8ï¼‰

**å…³é”®çº¦æŸ**:
- ç¬¬ä¸€å±‚å›ºå®štop_k=8ï¼ˆæ€»æ˜¯åŒ…å«ï¼‰
- åªåº”ç”¨äºæ’å…¥ä½ç½®ä¹‹åçš„blocks

**åº”ç”¨æ–¹å¼**: ç›´æ¥ä¿®æ”¹`block.mlp.top_k`å±æ€§ï¼ˆé›¶overheadï¼‰

### 4.3 Knob3: Transformer Blocks

**æ§åˆ¶å†…å®¹**: æ¿€æ´»çš„transformer blockæ•°é‡

**å†³ç­–æ—¶æœº**: åœ¨vision encoderä¹‹åï¼ŒLLMä¹‹å‰ï¼ˆä¸¤é˜¶æ®µï¼‰æˆ–ä¸Knob1åŒæ—¶ï¼ˆä¸€é˜¶æ®µï¼‰

**å®ç°æ–¹å¼**: Importance-based pruning

**è¾“å‡º**: 5ä¸ªé€‰æ‹©ï¼ˆ12, 13, 14, 15, 16 total blocksï¼‰

**å…³é”®è®¾è®¡**:
- **Total Blocks**: å€¼è¡¨ç¤ºæ€»blockæ•°ï¼ˆåŒ…æ‹¬ç¬¬ä¸€å±‚å’Œæ’å…¥ä½ç½®ä¹‹å‰çš„blocksï¼‰
- **åŠ¨æ€é€‰é¡¹**: æ ¹æ®æ’å…¥ä½ç½®åŠ¨æ€è°ƒæ•´å¯é€‰èŒƒå›´
- **ç¬¬ä¸€å±‚å›ºå®š**: æ€»æ˜¯åŒ…å«ç¬¬ä¸€å±‚ï¼ˆtop_k=8ï¼‰

**Importance Scoreç†è§£**:
- **Data-Agnostic**: Importance scoreä¸æ•°æ®æ¥æºæ— å…³ï¼ˆcoco vqaå’Œtext vqaçš„importance scoreæ¥è¿‘ï¼‰
- **Task-Dependent**: Importance scoreä¸ä»»åŠ¡ç±»å‹ç›¸å…³ï¼ˆscience-qaä¸VQAä»»åŠ¡çš„importance scoreå·®è·è¾ƒå¤§ï¼‰
- **åº”ç”¨ç­–ç•¥**: 
  - å¯¹äºç›¸åŒä»»åŠ¡ç±»å‹ï¼Œå¯ä»¥ä½¿ç”¨ç»Ÿä¸€çš„importance score
  - å¯¹äºä¸åŒä»»åŠ¡ç±»å‹ï¼Œå¯èƒ½éœ€è¦ä»»åŠ¡ç‰¹å®šçš„importance scoreæˆ–åŠ¨æ€é€‰æ‹©

**å…³é”®è®¾è®¡**: 
- Controlleråªé¢„æµ‹num_blocksï¼ˆ5ä¸ªé€‰æ‹©ï¼‰
- Block selectionåŸºäºé¢„è®¡ç®—çš„importance scoreï¼ˆç¡®å®šæ€§ï¼‰
- ä¸éœ€è¦å­¦ä¹ maskï¼ˆ2^16ç§å¯èƒ½ï¼‰
- å¯ä»¥æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©ä¸åŒçš„importance score

**å®ç°**:
```python
# Controlleré¢„æµ‹num_blocks
num_blocks = controller.predict_knob3(...)  # 8, 10, 12, 14, or 16

# æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©importance scoreï¼ˆå¯é€‰ï¼‰
task_type = infer_task_type(language_prompt)  # VQA, ScienceQA, etc.
importance_scores = get_importance_scores(task_type)

# åŸºäºimportance scoreé€‰æ‹©blocksï¼ˆç¡®å®šæ€§ï¼‰
selected_blocks = select_top_k_by_importance(importance_scores, num_blocks)

# åº”ç”¨mask
apply_block_mask(model, selected_blocks)
```

**ä¼˜åŠ¿**:
- è¾“å‡ºç©ºé—´ï¼š2^16 â†’ 5ï¼ˆå¤§å¹…ç®€åŒ–ï¼‰
- è®­ç»ƒç®€å•ï¼šåªéœ€è¦å­¦ä¹ 5ä¸ªé€‰æ‹©
- ç¨³å®šå¯é ï¼šåŸºäºé¢„è®¡ç®—çš„importance
- ä»»åŠ¡æ„ŸçŸ¥ï¼šå¯ä»¥æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©ä¸åŒçš„importance score

---

## 5. è¾“å…¥ç‰¹å¾è®¾è®¡

### 5.1 Stage 1è¾“å…¥

| ç‰¹å¾ | æå–æ–¹å¼ | ç»´åº¦ | è¯´æ˜ |
|------|---------|------|------|
| Language | Tokenizer + WTE + Mean pooling | (B, d_model) | ä»promptæå– |
| Budget | MLP encoder | (B, hidden_dim) | ä»latency budgetç¼–ç  |

**å…³é”®ç‚¹**ï¼š
- âœ… ä¸éœ€è¦vision featureï¼ˆvisionè¿˜æ²¡å¤„ç†ï¼‰
- âš ï¸ **è®¾è®¡é€‰é¡¹**: å¯ä»¥åªç”¨Budgetï¼ˆé€‰é¡¹Aï¼‰æˆ–Budget+Languageï¼ˆé€‰é¡¹Bï¼‰

### 5.2 Stage 2è¾“å…¥

| ç‰¹å¾ | æå–æ–¹å¼ | ç»´åº¦ | è¯´æ˜ |
|------|---------|------|------|
| Latency Token | LLM after insertion position | (B, d_model) | **æœ€åä¸€ä¸ªtoken**ï¼ˆåŒ…å«budget+vision+languageäº¤äº’ï¼‰ |

**å…³é”®ç‚¹**ï¼š
- âœ… **åªä½¿ç”¨Latency Token**: å·²ç»åŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯ï¼ˆbudget token + vision + languageç»è¿‡attentionï¼‰
- âœ… **æå–ä½ç½®**: åœ¨æ’å…¥ä½ç½®ä¹‹åçš„blockè¾“å‡ºä¸­æå–æœ€åä¸€ä¸ªtoken
- âœ… **ä¿¡æ¯å®Œæ•´æ€§**: Latency tokenå·²ç»åŒ…å«äº†budgetã€visionå’Œlanguageçš„äº¤äº’ä¿¡æ¯

---

## 6. è®­ç»ƒæ–¹æ³•

### 6.1 æ–¹æ³•å¯¹æ¯”

| æ–¹æ³• | Overhead | è®­ç»ƒæ—¶é—´ | æ ·æœ¬æ•ˆç‡ | å‡†ç¡®æ€§ | æ¨èåº¦ |
|------|---------|---------|---------|--------|--------|
| **Lookup Table** | 0 | 0 | N/A | ä¸­ç­‰ | â­â­â­ Baseline |
| **Supervised** | ä½ | å¿« | é«˜ | ä¸­ç­‰ | â­â­â­â­ Baseline |
| **GRPO** | ä½ | ä¸­ç­‰ | **æœ€é«˜** | é«˜ | â­â­â­â­â­ **æ¨è** |

### 6.2 æ¨èæ–¹æ¡ˆï¼šJoint Trainingï¼ˆå”¯ä¸€è®­ç»ƒæ–¹å¼ï¼‰

**Joint GRPO Training**:
- **æ•°æ®æ¥æº**: Online executionï¼ˆå®é™…æ•°æ®é›†æ ·æœ¬ï¼‰
- **è®­ç»ƒç›®æ ‡**: å­¦ä¹ accuracy-latency trade-off
- **ä¼˜ç‚¹**: é«˜æ•ˆæ ·æœ¬åˆ©ç”¨ï¼Œå¯ä»¥å­¦ä¹ å¤æ‚çº¦æŸï¼Œç«¯åˆ°ç«¯ä¼˜åŒ–
- **å…³é”®ç‰¹ç‚¹**: 
  - Stage1å’ŒStage2ä¸€èµ·è®­ç»ƒï¼Œå…±äº«rewardä¿¡å·
  - ä½¿ç”¨direct latency measurementï¼ˆhooksï¼‰
  - Batch size = 1 per sampleï¼ˆç¡®ä¿å‡†ç¡®æµ‹é‡ï¼‰

**è®­ç»ƒæµç¨‹**:
1. ä»å®é™…æ•°æ®é›†åŠ è½½æ ·æœ¬ï¼ˆimage + promptï¼‰
2. éšæœºé‡‡æ ·latency budgetï¼ˆ170-380msï¼‰
3. Stage1é¢„æµ‹tierå’Œinsertion position
4. è¿è¡Œvision encoderï¼ˆåŸºäºtierï¼‰
5. è¿è¡ŒLLMåˆ°insertion positionï¼Œæå–latency token
6. Stage2é¢„æµ‹top_kå’Œnum_blocks
7. æ‰§è¡Œå®Œæ•´æ¨¡å‹ï¼Œæµ‹é‡å®é™…latencyï¼ˆhooksï¼‰
8. è®¡ç®—accuracyå’Œreward
9. Joint GRPO lossæ›´æ–°ä¸¤ä¸ªcontroller

**å…³é”®è®¾è®¡**:
- **Direct Measurement**: ä½¿ç”¨PyTorch hooksç›´æ¥æµ‹é‡prefillå’Œdecode latency
- **Budget Token**: ç¼–ç ä¸ºd_modelç»´tokenï¼Œåœ¨prefillé˜¶æ®µæ‹¼æ¥åˆ°è¾“å…¥åºåˆ—
- **Decode Phase**: ä½¿ç”¨prefillé…ç½®ï¼Œä¸é‡æ–°è¿è¡Œcontroller

### 6.3 Latency Estimatorï¼ˆç‹¬ç«‹æ¨¡å—ï¼Œå¯é€‰ï¼‰

**æ³¨æ„**: Latency Estimatorä½œä¸ºç‹¬ç«‹æ¨¡å—ä¿ç•™ï¼Œä½†**å½“å‰controllerè®­ç»ƒä¸ä½¿ç”¨**ã€‚

**è®¾è®¡**: è½»é‡çº§MLPï¼ˆ2-3å±‚ï¼‰

**ç”¨é€”**: 
- å¯ä»¥ç”¨äºå¿«é€Ÿlatencyé¢„ä¼°ï¼ˆä¸ç”¨äºcontrollerè®­ç»ƒï¼‰
- å¯ä»¥ç”¨äºconfigurationæœç´¢å’Œä¼˜åŒ–
- å¯ä»¥ç”¨äºä¸åŒç¡¬ä»¶çš„latencyé¢„æµ‹

**è¯¦ç»†ä¿¡æ¯**: å‚è§`LATENCY_ESTIMATOR_DESIGN.md`ï¼ˆç‹¬ç«‹æ–‡æ¡£ï¼‰

---

## 7. Overheadåˆ†æ

### 7.1 Controllerå¼€é”€

**Stage 1 (Knob1)**:
- å‚æ•°é‡: ~10K-50Kï¼ˆå–å†³äºæ˜¯å¦ä½¿ç”¨Language featureï¼‰
- Latency: ~0.01-0.1ms
- å æ¯”: <0.01-0.1%

**Stage 2 (Knob2 & Knob3)**:
- å‚æ•°é‡: ~50K-200K
- Latency: ~0.1ms
- å æ¯”: <0.1%

**Total Controller Overhead**:
- å‚æ•°é‡: ~60K-250K
- Latency: ~0.11-0.2ms
- **å æ¯”: <0.1% of total inference**

### 7.2 èŠ‚çœçš„è®¡ç®—

- é€šè¿‡å‡å°‘top_k: èŠ‚çœ10-30% MoEè®¡ç®—
- é€šè¿‡è·³è¿‡blocks: èŠ‚çœ10-25% Transformerè®¡ç®—
- **Net benefit**: èŠ‚çœçš„è®¡ç®— >> controllerå¼€é”€

### 7.3 é›¶Overheadçš„Knobåº”ç”¨

**Top-Kåº”ç”¨**: ç›´æ¥ä¿®æ”¹å±æ€§ï¼ˆ`block.mlp.top_k = new_value`ï¼‰
- é›¶overhead
- ä¸å½±å“è®¡ç®—å›¾

**Block Maskåº”ç”¨**: ä½¿ç”¨BlockMaskWrapperï¼ˆpass-through for skipped blocksï¼‰
- è·³è¿‡blocksæ—¶åªåšidentity pass-through
- Overheadå¯å¿½ç•¥

---

## 8. å®ç°ç»†èŠ‚

### 8.1 åŠ¨æ€æ”¹å˜top_k

**å¯è¡Œæ€§**: âœ… å®Œå…¨å¯è¡Œï¼Œé›¶overhead

**å®ç°**:
```python
# ç›´æ¥ä¿®æ”¹å±æ€§ï¼ˆæœ€ç®€å•é«˜æ•ˆï¼‰
for i in range(4, 16):
    block = model.transformer.blocks[i]
    if hasattr(block, 'mlp') and hasattr(block.mlp, 'top_k'):
        block.mlp.top_k = new_top_k  # ç›´æ¥ä¿®æ”¹ï¼Œé›¶overhead
```

**å…³é”®ç‚¹**:
- `top_k`æ˜¯æ™®é€šPythonå±æ€§ï¼Œä¸åœ¨è®¡ç®—å›¾ä¸­
- å¯ä»¥ç›´æ¥ä¿®æ”¹ï¼Œä¸å½±å“è®¡ç®—å›¾

### 8.2 Importance-Based Block Selection

**å®ç°**: å‚è§`importance_based_block_selection.py`

**å…³é”®å‡½æ•°**:
```python
def select_blocks_by_importance(
    importance_scores: Dict[int, float],
    num_blocks: int,
) -> List[int]:
    """Select top-N most important blocks."""
    sorted_blocks = sorted(
        importance_scores.items(),
        key=lambda x: x[1],
        reverse=True
    )
    return [block_idx for block_idx, _ in sorted_blocks[:num_blocks]]
```

### 8.3 ä»£ç ç»“æ„

```
experiments/controller/
â”œâ”€â”€ minimal_controller.py              # Minimal-overhead controller
â”œâ”€â”€ two_stage_controller.py            # Two-stage controller (å½“å‰å®ç°)
â”œâ”€â”€ importance_based_block_selection.py  # Block selectionå·¥å…·
â”œâ”€â”€ feature_extractors.py              # ç‰¹å¾æå–
â”œâ”€â”€ latency_estimator.py               # Latency estimator
â””â”€â”€ ...
```

---

## 9. æ€§èƒ½æŒ‡æ ‡

### 9.1 OverheadæŒ‡æ ‡

- **Controller Latency**: <0.2ms
- **Controller Memory**: <1MB (parameters + activations)
- **Controller FLOPs**: <100K operations
- **Relative Overhead**: <0.1% of total inference

### 9.2 EffectivenessæŒ‡æ ‡

- **Accuracy Retention**: >95% (compared to full model)
- **Latency Reduction**: 20-50% (depending on budget)
- **Budget Adherence**: >90% (within budget)
- **Pareto Efficiency**: æ˜¾è‘—æå‡accuracy-latency Pareto frontier

### 9.3 EfficiencyæŒ‡æ ‡

- **Training Time**: <1 day (on 4 GPUs)
- **Sample Efficiency**: <10K samples for convergence
- **Inference Throughput**: >95% of baseline (minimal overhead)

---

## 10. å…³é”®è®¾è®¡å†³ç­–

### 10.1 ä¸¤é˜¶æ®µæ¶æ„

**å†³ç­–**: ä½¿ç”¨ä¸¤é˜¶æ®µé¢„æµ‹æ¶æ„

**ç†ç”±**:
- ç¬¦åˆç³»ç»Ÿæ‰§è¡Œæµç¨‹çº¦æŸ
- Knob1å¿…é¡»åœ¨vision encoderä¹‹å‰å†³å®š
- Knob2 & Knob3å¯ä»¥åœ¨vision encoderä¹‹åå†³å®š

### 10.2 Knob3: Importance-Based Pruning

**å†³ç­–**: ä½¿ç”¨importance-based pruningï¼Œè€Œä¸æ˜¯maské¢„æµ‹

**ç†ç”±**:
- ç®€åŒ–è¾“å‡ºç©ºé—´ï¼ˆ2^16 â†’ 5ï¼‰
- ç¡®å®šæ€§é€‰æ‹©ï¼Œç¨³å®šå¯é 
- æ•°æ®æ— å…³ï¼ˆåŸºäºé¢„è®¡ç®—çš„importanceï¼‰

### 10.3 è®­ç»ƒæ–¹æ³•: Joint GRPO

**å†³ç­–**: ä½¿ç”¨Joint GRPOåŒæ—¶è®­ç»ƒStage1å’ŒStage2

**ç†ç”±**:
- Critic-freeï¼Œè®­ç»ƒå¿«
- é«˜æ•ˆæ ·æœ¬åˆ©ç”¨
- å¯ä»¥å­¦ä¹ å¤æ‚çš„accuracy-latency trade-off
- ä¸¤ä¸ªé˜¶æ®µå…±äº«rewardï¼Œç«¯åˆ°ç«¯ä¼˜åŒ–
- å¯ä»¥åè°ƒä¸¤ä¸ªé˜¶æ®µçš„å†³ç­–

### 10.4 AdaLoRA-Inspiredè®¾è®¡ï¼ˆä¸¤ç§æ€è·¯ï¼‰

#### æ€è·¯1: ä¸¤é˜¶æ®µé¢„æµ‹ï¼ˆå½“å‰å®ç°ï¼‰

**æ¶æ„**:
```
Stage 1: Knob1 (Before Vision Encoder)
  - Input: Budget only æˆ– Budget + Language
  - Output: Vision Tokens Tier

â†“ Vision Encoder + Projector

Stage 2: Knob2 & Knob3 (After Projector)
  - Input: Vision + Language + Budget tokens
  - Method: å€Ÿç”¨LLMå‰3å±‚åšattentionèåˆ
  - Output: Top-K + Transformer Blocks (å13å±‚)
```

**ç‰¹ç‚¹**:
- ç¬¦åˆç³»ç»Ÿæ‰§è¡Œæµç¨‹
- åˆ©ç”¨LLMå‰3å±‚çš„è¡¨ç¤ºèƒ½åŠ›
- ä¸¤é˜¶æ®µå†³ç­–ï¼Œæ¸…æ™°æ˜ç¡®

**å®ç°**: å½“å‰`two_stage_controller.py`

#### æ€è·¯2: ä¸€é˜¶æ®µé¢„æµ‹ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰

**æ¶æ„**:
```
Single Stage: All Knobs (After Vision Encoder)
  - Input: Budget + Language + Vision (global crop)
  - Method: èåˆæ‰€æœ‰ç‰¹å¾ï¼Œç›´æ¥é¢„æµ‹ä¸‰ä¸ªknob
  - Output: Tier + Top-K + Transformer Blocks
```

**ç‰¹ç‚¹**:
- ä¸€æ¬¡æ€§å†³ç­–ï¼Œæ›´ç®€æ´
- éœ€è¦é¢å¤–çš„vision encoder passï¼ˆglobal cropï¼‰
- å¯ä»¥åˆ©ç”¨å®Œæ•´çš„è§†è§‰ä¿¡æ¯

**å®æ–½è®¡åˆ’**: ä¸¤ç§æ–¹æ¡ˆéƒ½ä¿ç•™ï¼Œåˆ†åˆ«å®ç°å’Œå¯¹æ¯”

### 10.5 å·²ç¡®è®¤å†³ç­–

**Knob1è®¾è®¡é€‰é¡¹**:
- âœ… é€‰é¡¹A: Budget-Onlyï¼ˆæœ€å°overheadï¼‰- ä¼˜å…ˆå®ç°
- âœ… é€‰é¡¹B: Budget + Language - è°ƒç ”Semantic Routeré›†æˆ
- âœ… é€‰é¡¹C: Budget + Language + Vision - éœ€è¦ä¼˜åŒ–å»ºè®®

**Importance Scoreç†è§£**:
- âœ… Data-Agnostic: ä¸æ•°æ®æ¥æºæ— å…³
- âœ… Task-Dependent: ä¸ä»»åŠ¡ç±»å‹ç›¸å…³
- âœ… åº”ç”¨ç­–ç•¥: æ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹©ä¸åŒçš„importance score

---

## é™„å½•

### A. ç›¸å…³æ–‡æ¡£

- `ANALYSIS.md`: æŠ€æœ¯åˆ†ææ–‡æ¡£
- `knob1_predictor_variants.md`: Knob1é¢„æµ‹å™¨çš„ä¸åŒå˜ä½“åˆ†æ
- `controller_implementation_details.md`: å®ç°ç»†èŠ‚å’Œå¯è¡Œæ€§åˆ†æ
- `IMPLEMENTATION_ROADMAP.md`: å®ç°è·¯çº¿å›¾
- `SEMANTIC_ROUTER_INTEGRATION.md`: Semantic Routeré›†æˆè°ƒç ”
- `ADALORA_DESIGNS.md`: AdaLoRA-Inspiredè®¾è®¡çš„ä¸¤ç§æ€è·¯

### B. ä»£ç å®ç°

- `experiments/controller/controller.py`: Controllerå®ç°ï¼ˆStage1å’ŒStage2ï¼‰
- `experiments/controller/joint_grpo_trainer.py`: Joint GRPOè®­ç»ƒå™¨
- `experiments/controller/train_joint_controller.py`: ä¸»è®­ç»ƒè„šæœ¬
- `experiments/controller/importance_based_block_selection.py`: Block selectionå·¥å…·
- `experiments/controller/model_forward_with_dynamic_stage2.py`: åŠ¨æ€forward pass

### C. å¤–éƒ¨èµ„æº

- **Semantic Router**: [https://github.com/aurelio-labs/semantic-router](https://github.com/aurelio-labs/semantic-router)
  - å¯ç”¨äºKnob1é€‰é¡¹Bçš„å¿«é€Ÿè¯­ä¹‰è·¯ç”±å†³ç­–
  - æ”¯æŒå¤šæ¨¡æ€è·¯ç”±
  - è¶…å¿«é€Ÿå†³ç­–ï¼ˆ<10msï¼‰

### D. è®¾è®¡å†å²

- **v1.0**: åŸå§‹è®¾è®¡ï¼ˆå•é˜¶æ®µï¼‰
- **v2.0**: ä¸¤é˜¶æ®µæ¶æ„ï¼ˆå½“å‰ç‰ˆæœ¬ï¼Œæ€è·¯1ï¼‰
- **v2.1**: SIGMETRICSä¼˜åŒ–ï¼ˆæœ€å°overheadï¼‰
- **v2.2**: æ·»åŠ ä¸€é˜¶æ®µæ–¹æ¡ˆï¼ˆæ€è·¯2ï¼‰å’ŒSemantic Routerè°ƒç ”

---

**æ–‡æ¡£ç»´æŠ¤**: æœ¬æ–‡æ¡£æ•´åˆäº†æ‰€æœ‰controllerè®¾è®¡æ–‡æ¡£ï¼ŒåŸºäºç°æœ‰ä»£ç å®ç°å’ŒSIGMETRICSæ ‡å‡†ã€‚å¦‚æœ‰ä¸ä¸€è‡´ï¼Œä»¥ä»£ç å®ç°ä¸ºå‡†ã€‚

