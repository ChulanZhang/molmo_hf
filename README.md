# MolmoE-1B

Molmoæ˜¯ç”±Allen Institute for AIå¼€å‘çš„å¼€æºè§†è§‰-è¯­è¨€æ¨¡å‹å®¶æ—ã€‚MolmoE-1Bæ˜¯åŸºäºæ··åˆä¸“å®¶(MoE)æ¶æ„çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰1.5Bæ´»è·ƒå‚æ•°å’Œ7.2Bæ€»å‚æ•°ï¼Œåœ¨åŒç­‰è§„æ¨¡çš„å¤šæ¨¡æ€æ¨¡å‹ä¸­å®ç°äº†ä¸šç•Œé¢†å…ˆçš„æ€§èƒ½ã€‚

**äº†è§£æ›´å¤š**: [åšå®¢æ–‡ç« ](https://molmo.allenai.org/blog) | [è®ºæ–‡](https://huggingface.co/papers/2409.17146) | [åœ¨çº¿Demo](https://molmo.allenai.org/)

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
molmo_hf/
â”œâ”€â”€ molmo/                      # ä¸»PythonåŒ…
â”‚   â”œâ”€â”€ models/                 # æ¨¡å‹æ¶æ„å’Œé…ç½®
â”‚   â”œâ”€â”€ preprocessors/          # æ•°æ®é¢„å¤„ç†æ¨¡å—
â”‚   â””â”€â”€ utils/                  # å·¥å…·å‡½æ•°
â”œâ”€â”€ configs/                    # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ model/                  # æ¨¡å‹é…ç½®
â”‚   â””â”€â”€ tokenizer/              # åˆ†è¯å™¨é…ç½®
â”œâ”€â”€ checkpoints/                # æ¨¡å‹æƒé‡æ–‡ä»¶
â”œâ”€â”€ experiments/                # å®éªŒè„šæœ¬
â”‚   â”œâ”€â”€ profiling/              # æ€§èƒ½åˆ†æå®éªŒ
â”‚   â””â”€â”€ motivate/               # åŸºç¡€å®éªŒæ¡†æ¶
â”œâ”€â”€ scripts/                    # ç¤ºä¾‹è¿è¡Œè„šæœ¬
â”œâ”€â”€ tests/                      # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ docs/                       # æ–‡æ¡£
â”œâ”€â”€ setup.py                    # å®‰è£…é…ç½®
â””â”€â”€ requirements.txt            # ä¾èµ–åˆ—è¡¨
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

**ä»æºç å®‰è£…ï¼ˆæ¨èç”¨äºå¼€å‘ï¼‰**

```bash
git clone <repository-url>
cd molmo_hf
# pip install -e .
pip install -e ".[experiments]"
```
## ğŸ§ª å®éªŒä¸æ€§èƒ½åˆ†æ

æœ¬é¡¹ç›®åŒ…å«å®Œæ•´çš„å®éªŒå¥—ä»¶ï¼Œç”¨äºåˆ†ææ¨¡å‹å»¶è¿Ÿå’Œæ€§èƒ½ã€‚

è¯¦ç»†æ–‡æ¡£è¯·å‚è€ƒï¼š[docs/experiment_usage.md](docs/experiment_usage.md)

### å¿«é€Ÿå¼€å§‹

**1. Motivation Study (Phase 1 & 2)**
```bash
bash experiments/motivate/run_phase1.sh
bash experiments/motivate/run_phase2.sh
```

**2. Profiling Experiments (Control Knobs)**
```bash
# Knob 1: Context Scaling
python experiments/profiling/knob1_tokens/exp_context_scaling.py

# Knob 2: MoE Top-K
python experiments/profiling/knob2_topk/exp_moe_topk.py

# Knob 3: Layer Skipping
python experiments/profiling/knob3_layers/exp_layer_skipping.py
```

### åŸºç¡€ä½¿ç”¨

```python
from transformers import AutoModelForCausalLM, AutoProcessor, GenerationConfig
from PIL import Image
import requests

# ä»æœ¬åœ°åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
model = AutoModelForCausalLM.from_pretrained(
    './molmo_hf',
    trust_remote_code=True,
    torch_dtype='auto',
    device_map='auto'
)

processor = AutoProcessor.from_pretrained(
    './molmo_hf',
    trust_remote_code=True,
    torch_dtype='auto',
    device_map='auto'
)

# å¤„ç†å›¾åƒå’Œæ–‡æœ¬
inputs = processor.process(
    images=[Image.open(requests.get("https://picsum.photos/id/237/536/354", stream=True).raw)],
    text="Describe this image."
)

# ç”Ÿæˆè¾“å…¥æ‰¹æ¬¡
inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}

# ç”Ÿæˆè¾“å‡º
output = model.generate_from_batch(
    inputs,
    GenerationConfig(max_new_tokens=200, stop_strings="